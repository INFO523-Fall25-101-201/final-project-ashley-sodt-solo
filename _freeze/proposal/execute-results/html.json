{
  "hash": "d2e67bf3ec341e8e16c600167b7afbb9",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Clustering Movement Patterns in Equine Exercise Sessions Using Anomaly Detection\nsubtitle: Proposal\nauthor:\n  - name: Ashley Sodt\n    affiliations:\n      - name: Applied Math PhD Student, University of Arizona\nformat:\n  html:\n    code-tools: true\n    code-overflow: wrap\n    code-line-numbers: true\n    embed-resources: true\neditor: visual\ncode-annotations: hover\nexecute:\n  warning: false\n  message: false\n---\n\nMy goal is to use unsupervised learning techniques to cluster EquiPro sessions and detect\nanomalies that may reflect behavioral irregularities, equipment issues, or potential reinjury.\n\nI aim to detect abnormal equine exercise sessions by clustering \nmovement-based features derived from processed EquiPro accelerometer data. Horses \nat the Al-Marah Equine Center are equipped with 7 accelerometers during exercise \nsessions on a lunge line at walk, trot, and canter. The EquiPro system outputs \ncalculated biomechanical metrics such as diagonal advanced placement, stride \nduration, and footfall duration. By modeling typical movement patterns for each \nhorse, I plan to identify exercise sessions that deviate significantly from a \nhorse’s baseline. Such anomalies may reflect behavioral irregularities, equipment \nmalfunction, pain, or potential reinjury. This is important in equine rehabilitation, \nwhere subtle changes in loading or symmetry can precede clinical signs of injury.\n\n::: {#load-pkgs .cell message='false' execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\n\nfrom IPython.display import display\n```\n:::\n\n\n## Dataset\n\nWe analyze stride-level biomechanical metrics recoreded by the EquiPro sessions\ncollected from three horses: Duque (14 sessions), Jackson (6 sessions), and Perseo (5 sessions).\nEach session is stored as a CSV file containing time-sampled movement variables. \nI chose this dataset because (1) it is directly \nrelevant to my research group’s goal of developing tools for equine rehabilitation \nmonitoring, and (2) the repeated-session structure makes it well suited for unsupervised \nlearning approaches.\n\n::: {#load-dataset .cell message='false' execution_count=2}\n``` {.python .cell-code}\n# Load one example Duque session to illustrate the raw data structure\n\ndf_duque = pd.read_csv(\"Horses/Duque/20240626T082743-Duque-results.csv\")\n\nprint(\"\\nExample Duque session from EquiPro:\")\nprint(f\"  - dataset shape: {df_duque.shape}\")\nprint(f\"  - number of rows: {df_duque.shape[0]}\")\nprint(f\"  - number of columns: {df_duque.shape[1]}\")\n\nprint(\"\\nFirst few rows:\")\ndisplay(df_duque.head())\n\nprint(\"\\nData types:\")\ndisplay(df_duque.dtypes)\n\nprint(\"\\nSummary statistics:\")\n\n# Select numeric columns\nnumeric_cols = df_duque.select_dtypes(include=\"number\").columns\n\n# Drop 'segment' if it’s there\nnumeric_cols = [c for c in numeric_cols if c != \"segment\"]\n\ndisplay(df_duque[numeric_cols].describe())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nExample Duque session from EquiPro:\n  - dataset shape: (180, 80)\n  - number of rows: 180\n  - number of columns: 80\n\nFirst few rows:\n```\n:::\n\n::: {#load-dataset-1 .cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segment</th>\n      <th>gait</th>\n      <th>direction</th>\n      <th>surface</th>\n      <th>stride_dur</th>\n      <th>duty_factor</th>\n      <th>stance_dur_LF</th>\n      <th>stance_dur_RF</th>\n      <th>stance_dur_LH</th>\n      <th>stance_dur_RH</th>\n      <th>...</th>\n      <th>si_up_sac</th>\n      <th>hiphike_swing</th>\n      <th>hiphike_stance</th>\n      <th>horse_name</th>\n      <th>measurement</th>\n      <th>exam_type</th>\n      <th>exam_purpose</th>\n      <th>flexion_test</th>\n      <th>diagnostic_analgesia</th>\n      <th>inconclusive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>walk</td>\n      <td>left</td>\n      <td>soft</td>\n      <td>1.3444</td>\n      <td>64.4371</td>\n      <td>0.890</td>\n      <td>0.870</td>\n      <td>0.865</td>\n      <td>0.840</td>\n      <td>...</td>\n      <td>0.3658</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Duque</td>\n      <td>20240626T082743_logfile.itlog</td>\n      <td>In hand</td>\n      <td>Research</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>walk</td>\n      <td>left</td>\n      <td>soft</td>\n      <td>1.3631</td>\n      <td>63.8211</td>\n      <td>0.865</td>\n      <td>0.900</td>\n      <td>0.855</td>\n      <td>0.860</td>\n      <td>...</td>\n      <td>0.3110</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Duque</td>\n      <td>20240626T082743_logfile.itlog</td>\n      <td>In hand</td>\n      <td>Research</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>walk</td>\n      <td>left</td>\n      <td>soft</td>\n      <td>1.4238</td>\n      <td>65.0491</td>\n      <td>0.950</td>\n      <td>0.960</td>\n      <td>0.910</td>\n      <td>0.885</td>\n      <td>...</td>\n      <td>0.3212</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Duque</td>\n      <td>20240626T082743_logfile.itlog</td>\n      <td>In hand</td>\n      <td>Research</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>walk</td>\n      <td>left</td>\n      <td>soft</td>\n      <td>1.3925</td>\n      <td>64.5510</td>\n      <td>0.905</td>\n      <td>0.930</td>\n      <td>0.855</td>\n      <td>0.905</td>\n      <td>...</td>\n      <td>0.1506</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Duque</td>\n      <td>20240626T082743_logfile.itlog</td>\n      <td>In hand</td>\n      <td>Research</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>walk</td>\n      <td>left</td>\n      <td>soft</td>\n      <td>1.4337</td>\n      <td>65.2012</td>\n      <td>0.955</td>\n      <td>0.955</td>\n      <td>0.880</td>\n      <td>0.950</td>\n      <td>...</td>\n      <td>-0.0292</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Duque</td>\n      <td>20240626T082743_logfile.itlog</td>\n      <td>In hand</td>\n      <td>Research</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 80 columns</p>\n</div>\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nData types:\n```\n:::\n\n::: {#load-dataset-2 .cell-output .cell-output-display}\n```\nsegment                   int64\ngait                     object\ndirection                object\nsurface                  object\nstride_dur              float64\n                         ...   \nexam_type                object\nexam_purpose             object\nflexion_test            float64\ndiagnostic_analgesia    float64\ninconclusive            float64\nLength: 80, dtype: object\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSummary statistics:\n```\n:::\n\n::: {#load-dataset-3 .cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stride_dur</th>\n      <th>duty_factor</th>\n      <th>stance_dur_LF</th>\n      <th>stance_dur_RF</th>\n      <th>stance_dur_LH</th>\n      <th>stance_dur_RH</th>\n      <th>swing_dur_LF</th>\n      <th>swing_dur_RF</th>\n      <th>swing_dur_LH</th>\n      <th>swing_dur_RH</th>\n      <th>...</th>\n      <th>max_diff_wth</th>\n      <th>si_up_wth</th>\n      <th>min_diff_sac</th>\n      <th>max_diff_sac</th>\n      <th>si_up_sac</th>\n      <th>hiphike_swing</th>\n      <th>hiphike_stance</th>\n      <th>flexion_test</th>\n      <th>diagnostic_analgesia</th>\n      <th>inconclusive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>180.000000</td>\n      <td>...</td>\n      <td>176.000000</td>\n      <td>177.000000</td>\n      <td>178.000000</td>\n      <td>176.000000</td>\n      <td>179.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.963107</td>\n      <td>54.579687</td>\n      <td>0.568389</td>\n      <td>0.559389</td>\n      <td>0.514639</td>\n      <td>0.534889</td>\n      <td>0.395111</td>\n      <td>0.404083</td>\n      <td>0.446528</td>\n      <td>0.427972</td>\n      <td>...</td>\n      <td>1.488275</td>\n      <td>-0.122714</td>\n      <td>7.669183</td>\n      <td>-3.365421</td>\n      <td>0.107437</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.262439</td>\n      <td>7.311467</td>\n      <td>0.221720</td>\n      <td>0.229814</td>\n      <td>0.229520</td>\n      <td>0.227791</td>\n      <td>0.050078</td>\n      <td>0.040903</td>\n      <td>0.044156</td>\n      <td>0.041779</td>\n      <td>...</td>\n      <td>8.932586</td>\n      <td>0.217380</td>\n      <td>14.673789</td>\n      <td>6.850741</td>\n      <td>0.184641</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.726900</td>\n      <td>46.336100</td>\n      <td>0.350000</td>\n      <td>0.345000</td>\n      <td>0.265000</td>\n      <td>0.315000</td>\n      <td>0.305000</td>\n      <td>0.330000</td>\n      <td>0.350000</td>\n      <td>0.355000</td>\n      <td>...</td>\n      <td>-16.488600</td>\n      <td>-0.616400</td>\n      <td>-32.960600</td>\n      <td>-18.834500</td>\n      <td>-0.313200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.769400</td>\n      <td>48.422575</td>\n      <td>0.403750</td>\n      <td>0.385000</td>\n      <td>0.335000</td>\n      <td>0.370000</td>\n      <td>0.360000</td>\n      <td>0.375000</td>\n      <td>0.410000</td>\n      <td>0.400000</td>\n      <td>...</td>\n      <td>-6.055375</td>\n      <td>-0.268000</td>\n      <td>1.107650</td>\n      <td>-8.561275</td>\n      <td>-0.013300</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.796250</td>\n      <td>50.770600</td>\n      <td>0.435000</td>\n      <td>0.420000</td>\n      <td>0.382500</td>\n      <td>0.387500</td>\n      <td>0.377500</td>\n      <td>0.400000</td>\n      <td>0.445000</td>\n      <td>0.412500</td>\n      <td>...</td>\n      <td>3.138850</td>\n      <td>-0.116900</td>\n      <td>11.673800</td>\n      <td>-3.368450</td>\n      <td>0.141800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.266225</td>\n      <td>63.661100</td>\n      <td>0.820000</td>\n      <td>0.825000</td>\n      <td>0.780000</td>\n      <td>0.796250</td>\n      <td>0.435000</td>\n      <td>0.435000</td>\n      <td>0.480000</td>\n      <td>0.451250</td>\n      <td>...</td>\n      <td>8.718675</td>\n      <td>0.013400</td>\n      <td>17.654575</td>\n      <td>1.765275</td>\n      <td>0.225950</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.975600</td>\n      <td>72.720200</td>\n      <td>1.585000</td>\n      <td>1.335000</td>\n      <td>1.380000</td>\n      <td>1.450000</td>\n      <td>0.520000</td>\n      <td>0.610000</td>\n      <td>0.555000</td>\n      <td>0.535000</td>\n      <td>...</td>\n      <td>19.448700</td>\n      <td>0.648100</td>\n      <td>36.335700</td>\n      <td>13.080800</td>\n      <td>0.748000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 72 columns</p>\n</div>\n```\n:::\n:::\n\n\n## Questions\n\nWhich exercise sessions significantly deviate from each horse’s baseline distribution, \nand which biomechanical variables contribute most strongly to those deviations?\n\nHow do different unsupervised anomaly-detection methods (z-score thresholding, k-means cluster distance, \nand Isolation Forest) compare in identifying abnormal sessions, and to what extent do they \nagree or disagree on which sessions are flagged as anomalous?\n\n## Analysis plan\n\n \nFor each exercise session, I will load the corresponding EquiPro CSV file and extract \nbiomechanical variables relevant to symmetry, gait, and stride mechanics. To create \nsession-level features, I will summarize each variable using statistics like mean, \nstandard deviation, interquartile range, etc. These engineered features will form \na feature matrix for each horse where each row is a session and each column is a \nbiomechanical descriptor.\n\nI will then model each horse's baseline movement patterns. I will standardize all \nfeatures within each horse by converting them to z-scores in order to remove scale \ndifferences. This will provide a clear reference point. Features consistently close \nto zero after standardization indicate typical behavior, but large positive or negative \nvalues indicate potential deviations. These standardized distributions form the baseline \nagainst which the anomaly-detection methods will evaluate whether any given session \ndeparts significantly from a horse’s typical movement pattern.\n\nAfter establishing the baselines for each horse using z-scores, I will apply three \nunsupervised anomaly-detection methods to identify sessions that deviate from typical \nmovement. Z-score analysis will allow me to flag sessions where specific features \nare unusually high or low relative to baseline distribution. K-means clustering will \nidentify anomalies based on their distance from cluster centers in the multivariate \nfeature space. Isolation Forest will give a measure of how isolated a session is from \nthe rest. Each method will produce a numerical anomaly score and a corresponding label \nindicating whether the session is considered abnormal.\n\nI will then compare the results between the three methods. I will look for overlap \nbetween flagged sessions, sessions consistently identified as outliers, and note where \nthe methods differ. I will also interpret the identified anomalies as they relate to \nbiomechanical variables. I will inspect which specific features contribute most strongly \nto deviations from baseline. This could give insight as to possible explanations for \ndeviations: behavioral irregularities, equipment malfunction, pain, or potential reinjury.\n\nNo external datasets will be merged.\n\nblah\nFor each horse, I will compile \nthese sessions into one file with session-level features for analysis. I chose this \ndataset because it is directly relevant to my graduate research and because it is \nwell suited for unsupervised analysis. Session-level features will allow me to \nestablish per-horse baseline distributions and apply methods such as z-score \nanalysis, k-means clustering, and Isolation Forest to quantify deviations. By \nidentifying and visualizing sessions with anomalies over time, this project will \nexplore whether data-driven monitoring can help track rehabilitation progress and \nhighlight sessions that warrant further investigation.\n\n",
    "supporting": [
      "proposal_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}